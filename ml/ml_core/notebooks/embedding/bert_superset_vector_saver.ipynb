{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252f1bc47a6726ac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:49:49.582294Z",
     "start_time": "2024-07-02T10:49:49.576726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['run.sh',\n 'requirements.txt',\n 'ml',\n '.idea',\n 'bot_discord',\n 'venv',\n '.git',\n 'log',\n '.gitignore']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "if '.git' not in os.listdir():\n",
    "    os.chdir('./../../../../')\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:49:58.300791Z",
     "start_time": "2024-07-02T10:49:50.560605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:49:52.606806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 12:49:52.895210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 12:49:52.896922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 12:49:53.280812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 12:49:55.202766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"embedder_data\": \"small_bert_bert_en_uncased_L-4_H-512_A-8\",\n",
    "    \"dataset\": \"fr_hf.csv\"\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:49:59.146009Z",
     "start_time": "2024-07-02T10:49:59.143063Z"
    }
   },
   "id": "c8c732d75b962571",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_folder_src = 'ml/ml_core/data/processed/'\n",
    "data_path_src = f'{data_folder_src}{params_grid[\"dataset\"]}'\n",
    "\n",
    "vector_path = f'ml/ml_core/embedded_vector/{params_grid[\"embedder_data\"]}_{params_grid[\"dataset\"]}'\n",
    "vector_x_dst = f'{vector_path}.x.npy'\n",
    "vector_y_dst = f'{vector_path}.y.npy'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:49:59.848974Z",
     "start_time": "2024-07-02T10:49:59.844749Z"
    }
   },
   "id": "3f1ffbbe1322a51b",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "3d946bd3803cbf47",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581097380ddb6dcb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:50:01.425280Z",
     "start_time": "2024-07-02T10:50:01.417848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "#bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/1',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9374564c814f9b68",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:50:02.183616Z",
     "start_time": "2024-07-02T10:50:02.179303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67f513f536c5c68",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:50:06.188922Z",
     "start_time": "2024-07-02T10:50:02.741056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:50:03.582510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.118236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.118285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.120000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.120060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.120088: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.449107: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.449277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.449336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 12:50:04.449487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 12:50:04.449580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1028 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on DESKTOP-9P9JTBP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3061\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m   3060\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3061\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_cache\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m   3062\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m bert_preprocess_model \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKerasLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtfhub_handle_preprocess\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:165\u001B[0m, in \u001B[0;36mKerasLayer.__init__\u001B[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_shape \u001B[38;5;241m=\u001B[39m data_structures\u001B[38;5;241m.\u001B[39mNoDependency(\n\u001B[1;32m    162\u001B[0m       _convert_nest_to_shapes(output_shape))\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func \u001B[38;5;241m=\u001B[39m \u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_hub_module_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:467\u001B[0m, in \u001B[0;36mload_module\u001B[0;34m(handle, tags, load_options)\u001B[0m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:  \u001B[38;5;66;03m# Expected before TF2.4.\u001B[39;00m\n\u001B[1;32m    466\u001B[0m       set_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodule_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_load_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/module_v2.py:126\u001B[0m, in \u001B[0;36mload\u001B[0;34m(handle, tags, options)\u001B[0m\n\u001B[1;32m    123\u001B[0m   obj \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mload_v2(\n\u001B[1;32m    124\u001B[0m       module_path, tags\u001B[38;5;241m=\u001B[39mtags, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 126\u001B[0m   obj \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m obj\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m is_hub_module_v1  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:912\u001B[0m, in \u001B[0;36mload\u001B[0;34m(export_dir, tags, options)\u001B[0m\n\u001B[1;32m    910\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(export_dir, os\u001B[38;5;241m.\u001B[39mPathLike):\n\u001B[1;32m    911\u001B[0m   export_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(export_dir)\n\u001B[0;32m--> 912\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mload_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:1042\u001B[0m, in \u001B[0;36mload_partial\u001B[0;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minit_scope():\n\u001B[1;32m   1041\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1042\u001B[0m     loader \u001B[38;5;241m=\u001B[39m \u001B[43mLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_graph_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaved_model_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mckpt_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1044\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   1045\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1046\u001B[0m         \u001B[38;5;28mstr\u001B[39m(err) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m You may be trying to load on a different device \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1047\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom the computational device. Consider setting the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1048\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1049\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto the io_device such as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/job:localhost\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:161\u001B[0m, in \u001B[0;36mLoader.__init__\u001B[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proto \u001B[38;5;241m=\u001B[39m object_graph_proto\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_dir \u001B[38;5;241m=\u001B[39m export_dir\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 161\u001B[0m     \u001B[43mfunction_deserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_function_def_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43msaved_object_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrapper_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_WrapperFunction\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# captures.\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restored_concrete_functions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/function_deserialization.py:456\u001B[0m, in \u001B[0;36mload_function_def_library\u001B[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001B[39;00m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# import).\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m--> 456\u001B[0m   func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_def_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_input_signature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_input_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# custom gradients)\u001B[39;00m\n\u001B[1;32m    462\u001B[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/function_def_to_graph.py:91\u001B[0m, in \u001B[0;36mfunction_def_to_graph\u001B[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001B[0m\n\u001B[1;32m     88\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m         input_shapes\u001B[38;5;241m.\u001B[39mappend(input_shape)\n\u001B[0;32m---> 91\u001B[0m graph_def, nested_to_flat_tensor_name \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_to_graph_def\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_library_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_library_functions\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m func_graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[1;32m     96\u001B[0m   \u001B[38;5;66;03m# Add all function nodes to the graph.\u001B[39;00m\n\u001B[1;32m     97\u001B[0m   importer\u001B[38;5;241m.\u001B[39mimport_graph_def_for_function(\n\u001B[1;32m     98\u001B[0m       graph_def, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, propagate_device_spec\u001B[38;5;241m=\u001B[39mpropagate_device_spec)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/function_def_to_graph.py:330\u001B[0m, in \u001B[0;36mfunction_def_to_graph_def\u001B[0;34m(fdef, input_shapes, include_library_functions)\u001B[0m\n\u001B[1;32m    328\u001B[0m       graph_def\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mgradient\u001B[38;5;241m.\u001B[39mextend([grad_def])\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 330\u001B[0m   op_def \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m op_def\u001B[38;5;241m.\u001B[39mattr:\n\u001B[1;32m    333\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m attr\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3064\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m   3061\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n\u001B[1;32m   3062\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m   3063\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m] \u001B[38;5;241m=\u001B[39m op_def_pb2\u001B[38;5;241m.\u001B[39mOpDef\u001B[38;5;241m.\u001B[39mFromString(\n\u001B[0;32m-> 3064\u001B[0m       \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3065\u001B[0m   )\n\u001B[1;32m   3066\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Op type not registered 'CaseFoldUTF8' in binary running on DESKTOP-9P9JTBP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49d8c2bd95e8ddf5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:25:12.867178Z",
     "start_time": "2024-07-02T10:25:03.106388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:25:12.048043: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 62509056 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98bb3e5fa6526cfb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:25:30.754615Z",
     "start_time": "2024-07-02T10:25:29.383378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceci est un test']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:25:30.081791: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.081898: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.081941: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.082186: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.082311: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.083476: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.083619: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.083768: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.254290: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.537970: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.538445: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.540334: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.541518: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.541586: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.542200: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.547938: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 12:25:30.548377: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.9818011   0.89277554  0.23231454  0.01589974  0.1806383   0.9957792\n",
      "  0.99798256  0.33106488 -0.02497336 -0.9987041  -0.09310168 -0.26330215]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.42536885 -0.0092841   0.90875703 ... -1.3789577   0.867938\n",
      "   0.19424458]\n",
      " [-0.43141297  0.13562825 -0.30347514 ... -1.0568973   0.5224188\n",
      "  -0.28293064]\n",
      " [-0.66645205 -0.39647132  0.6052308  ... -1.3264837   0.34678963\n",
      "   0.13612354]\n",
      " ...\n",
      " [-0.0633131   0.22402436  1.0188394  ... -0.84042495  0.38894445\n",
      "   0.20893508]\n",
      " [ 0.12264241  0.4450482   0.7040574  ... -0.84877586  0.8868514\n",
      "   0.201817  ]\n",
      " [ 0.1116228   0.3624912   0.81944793 ... -0.7872127   0.8446359\n",
      "   0.12332332]]\n"
     ]
    }
   ],
   "source": [
    "text = np.expand_dims(\"ceci est un test\", axis=0)\n",
    "print(text)\n",
    "text_encoded = bert_preprocess_model(text)\n",
    "text_encoded\n",
    "bert_results = bert_model(text_encoded)\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4209390b020a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cda597a675bb1ba2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:25:32.664810Z",
     "start_time": "2024-07-02T10:25:32.613649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text  labels target  \\\n0      On ne peut pas faire confiance aux musulmans c...       1  islam   \n1         Les musulmans ne sont pas dignes de confiance.       1  islam   \n2              Vous ne devriez pas croire les musulmans.       1  islam   \n3      Les musulmans empêchent les gens de manger pen...       1  islam   \n4      Les musulmans ne laissent pas les gens s'en pr...       1  islam   \n...                                                  ...     ...    ...   \n18066                         Kevin câest un sal noir.       1    NaN   \n18067  bougnoule bamboula sale arabe , elle est belle...       1    NaN   \n18068         @USER Tu viens de le traiter de sal noir ?       1    NaN   \n18069                                      SAL NOIR LINK       1    NaN   \n18070                                 Sal Noir LINK LINK       1    NaN   \n\n        source dataset  nb_annotators  tweet_id  \n0          NGO   CONAN              1       NaN  \n1          NGO   CONAN              1       NaN  \n2          NGO   CONAN              1       NaN  \n3          NGO   CONAN              1       NaN  \n4          NGO   CONAN              1       NaN  \n...        ...     ...            ...       ...  \n18066  Twitter     FTR              2       NaN  \n18067  Twitter     FTR              2       NaN  \n18068  Twitter     FTR              2       NaN  \n18069  Twitter     FTR              2       NaN  \n18070  Twitter     FTR              2       NaN  \n\n[18071 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n      <th>target</th>\n      <th>source</th>\n      <th>dataset</th>\n      <th>nb_annotators</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>On ne peut pas faire confiance aux musulmans c...</td>\n      <td>1</td>\n      <td>islam</td>\n      <td>NGO</td>\n      <td>CONAN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Les musulmans ne sont pas dignes de confiance.</td>\n      <td>1</td>\n      <td>islam</td>\n      <td>NGO</td>\n      <td>CONAN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Vous ne devriez pas croire les musulmans.</td>\n      <td>1</td>\n      <td>islam</td>\n      <td>NGO</td>\n      <td>CONAN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Les musulmans empêchent les gens de manger pen...</td>\n      <td>1</td>\n      <td>islam</td>\n      <td>NGO</td>\n      <td>CONAN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Les musulmans ne laissent pas les gens s'en pr...</td>\n      <td>1</td>\n      <td>islam</td>\n      <td>NGO</td>\n      <td>CONAN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18066</th>\n      <td>Kevin câest un sal noir.</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Twitter</td>\n      <td>FTR</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18067</th>\n      <td>bougnoule bamboula sale arabe , elle est belle...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Twitter</td>\n      <td>FTR</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18068</th>\n      <td>@USER Tu viens de le traiter de sal noir ?</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Twitter</td>\n      <td>FTR</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18069</th>\n      <td>SAL NOIR LINK</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Twitter</td>\n      <td>FTR</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18070</th>\n      <td>Sal Noir LINK LINK</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Twitter</td>\n      <td>FTR</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>18071 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(data_path_src)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d86b3a33f2e60",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4811628c43744431",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:25:34.114350Z",
     "start_time": "2024-07-02T10:25:34.110689Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    text = np.expand_dims(text, axis=0)\n",
    "    text_encoded = bert_preprocess_model(text)\n",
    "    bert_results = bert_model(text_encoded)\n",
    "\n",
    "    return bert_results[\"pooled_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18071/18071 [06:12<00:00, 48.52it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc='Loading data')\n",
    "ds['vector'] = ds['text'].progress_apply(text_to_vector)\n",
    "\n",
    "X = np.vstack(ds['vector'])\n",
    "y = ds['labels'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:31:50.126412Z",
     "start_time": "2024-07-02T10:25:35.716334Z"
    }
   },
   "id": "919b332d959084a6",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "7b718cecf9585fb1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## building and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ac62597164bde",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec354f696f24a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eee4f2d23f45322e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:31:55.969446Z",
     "start_time": "2024-07-02T10:31:55.899185Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.save(vector_x_dst, X)\n",
    "np.save(vector_y_dst, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c753464d73b3dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:47.583103Z",
     "start_time": "2024-07-02T08:24:47.580900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
