{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:06:40.092988Z",
     "start_time": "2024-07-02T10:06:40.089817Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"embedder_data\": \"small_bert_bert_en_uncased_L-4_H-512_A-8\",\n",
    "    \"dataset\": \"fr_hf.csv\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:06:40.736523Z",
     "start_time": "2024-07-02T10:06:40.733074Z"
    }
   },
   "id": "574b6993e9911341",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "#bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/1',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:11:35.397646Z",
     "start_time": "2024-07-02T10:11:35.384020Z"
    }
   },
   "id": "cf02b7db8efd6b2d",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on DESKTOP-9P9JTBP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3061\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m   3060\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3061\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_cache\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m   3062\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m bert_preprocess_model \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKerasLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtfhub_handle_preprocess\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:165\u001B[0m, in \u001B[0;36mKerasLayer.__init__\u001B[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_shape \u001B[38;5;241m=\u001B[39m data_structures\u001B[38;5;241m.\u001B[39mNoDependency(\n\u001B[1;32m    162\u001B[0m       _convert_nest_to_shapes(output_shape))\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func \u001B[38;5;241m=\u001B[39m \u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_hub_module_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:467\u001B[0m, in \u001B[0;36mload_module\u001B[0;34m(handle, tags, load_options)\u001B[0m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:  \u001B[38;5;66;03m# Expected before TF2.4.\u001B[39;00m\n\u001B[1;32m    466\u001B[0m       set_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodule_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_load_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/module_v2.py:126\u001B[0m, in \u001B[0;36mload\u001B[0;34m(handle, tags, options)\u001B[0m\n\u001B[1;32m    123\u001B[0m   obj \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mload_v2(\n\u001B[1;32m    124\u001B[0m       module_path, tags\u001B[38;5;241m=\u001B[39mtags, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 126\u001B[0m   obj \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m obj\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m is_hub_module_v1  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:912\u001B[0m, in \u001B[0;36mload\u001B[0;34m(export_dir, tags, options)\u001B[0m\n\u001B[1;32m    910\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(export_dir, os\u001B[38;5;241m.\u001B[39mPathLike):\n\u001B[1;32m    911\u001B[0m   export_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(export_dir)\n\u001B[0;32m--> 912\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mload_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:1042\u001B[0m, in \u001B[0;36mload_partial\u001B[0;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minit_scope():\n\u001B[1;32m   1041\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1042\u001B[0m     loader \u001B[38;5;241m=\u001B[39m \u001B[43mLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_graph_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaved_model_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mckpt_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1044\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   1045\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1046\u001B[0m         \u001B[38;5;28mstr\u001B[39m(err) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m You may be trying to load on a different device \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1047\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom the computational device. Consider setting the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1048\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1049\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto the io_device such as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/job:localhost\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:161\u001B[0m, in \u001B[0;36mLoader.__init__\u001B[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proto \u001B[38;5;241m=\u001B[39m object_graph_proto\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_dir \u001B[38;5;241m=\u001B[39m export_dir\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 161\u001B[0m     \u001B[43mfunction_deserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_function_def_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43msaved_object_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrapper_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_WrapperFunction\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# captures.\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restored_concrete_functions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/saved_model/function_deserialization.py:456\u001B[0m, in \u001B[0;36mload_function_def_library\u001B[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001B[39;00m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# import).\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m--> 456\u001B[0m   func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_def_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_input_signature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_input_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# custom gradients)\u001B[39;00m\n\u001B[1;32m    462\u001B[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/function_def_to_graph.py:91\u001B[0m, in \u001B[0;36mfunction_def_to_graph\u001B[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001B[0m\n\u001B[1;32m     88\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m         input_shapes\u001B[38;5;241m.\u001B[39mappend(input_shape)\n\u001B[0;32m---> 91\u001B[0m graph_def, nested_to_flat_tensor_name \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_to_graph_def\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_library_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_library_functions\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m func_graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[1;32m     96\u001B[0m   \u001B[38;5;66;03m# Add all function nodes to the graph.\u001B[39;00m\n\u001B[1;32m     97\u001B[0m   importer\u001B[38;5;241m.\u001B[39mimport_graph_def_for_function(\n\u001B[1;32m     98\u001B[0m       graph_def, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, propagate_device_spec\u001B[38;5;241m=\u001B[39mpropagate_device_spec)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/function_def_to_graph.py:330\u001B[0m, in \u001B[0;36mfunction_def_to_graph_def\u001B[0;34m(fdef, input_shapes, include_library_functions)\u001B[0m\n\u001B[1;32m    328\u001B[0m       graph_def\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mgradient\u001B[38;5;241m.\u001B[39mextend([grad_def])\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 330\u001B[0m   op_def \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m op_def\u001B[38;5;241m.\u001B[39mattr:\n\u001B[1;32m    333\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m attr\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3064\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m   3061\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n\u001B[1;32m   3062\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m   3063\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m] \u001B[38;5;241m=\u001B[39m op_def_pb2\u001B[38;5;241m.\u001B[39mOpDef\u001B[38;5;241m.\u001B[39mFromString(\n\u001B[0;32m-> 3064\u001B[0m       \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3065\u001B[0m   )\n\u001B[1;32m   3066\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Op type not registered 'CaseFoldUTF8' in binary running on DESKTOP-9P9JTBP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:12:09.009668Z",
     "start_time": "2024-07-02T10:12:07.867267Z"
    }
   },
   "id": "b6f9fda3888dea36",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_folder_src = './../../data/processed/'\n",
    "data_path_src = f'{data_folder_src}{params_grid[\"dataset\"]}'\n",
    "\n",
    "vector_path = f'./../../embedded_vector/{params_grid[\"embedder_data\"]}_{params_grid[\"dataset\"]}'\n",
    "vector_x_dst = f'{vector_path}.x.npy'\n",
    "vector_y_dst = f'{vector_path}.y.npy'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06acd0d43aa1174",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "510f23ee36f88227",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_preprocess_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "657b3d0942fb668f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "ds = pd.read_csv(data_path_src)\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c29c54a6272f571",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def text_to_vector(text):\n",
    "    words = text.split(' ')\n",
    "    word_vectors = [word for word in words if word in words]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(300)\n",
    "    return np.mean(word_vectors, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34238ecb35592802",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tqdm.pandas(desc='Loading data')\n",
    "ds['vector'] = ds['text'].progress_apply(text_to_vector)\n",
    "\n",
    "X = np.vstack(ds['vector'])\n",
    "y = ds['labels'].values\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f540ba1a1e28d9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(vector_x_dst, X)\n",
    "np.save(vector_y_dst, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b77d30b2083616",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21e9181af470f97a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
