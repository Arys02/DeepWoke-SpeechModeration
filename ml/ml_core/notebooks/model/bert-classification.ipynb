{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['run.sh',\n 'requirements.txt',\n 'ml',\n '.idea',\n 'bot_discord',\n 'venv',\n '.git',\n 'log',\n '.gitignore']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "if '.git' not in os.listdir(): \n",
    "    os.chdir('./../../../../')\n",
    "os.listdir()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:01:26.074541Z",
     "start_time": "2024-07-02T09:01:26.064767Z"
    }
   },
   "id": "252f1bc47a6726ac",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:01:31.305073Z",
     "start_time": "2024-07-02T09:01:27.095768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 11:01:27.676395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 11:01:27.691605: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 11:01:27.691638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 11:01:27.701059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 11:01:28.648369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "import fasttext\n",
    "import keras_core as keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_core.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d946bd3803cbf47",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import BERT model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "#bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/1',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:01:38.957955Z",
     "start_time": "2024-07-02T09:01:38.939872Z"
    }
   },
   "id": "581097380ddb6dcb",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfhub_handle_preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:28:16.621199Z",
     "start_time": "2024-07-02T09:28:16.616390Z"
    }
   },
   "id": "9374564c814f9b68",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 11:01:43.230232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.600099: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.600148: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.602226: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.602307: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.602341: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.787373: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.787463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.787472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 11:01:43.787513: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 11:01:43.787536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7090 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:01:57.291877Z",
     "start_time": "2024-07-02T09:01:42.159663Z"
    }
   },
   "id": "e67f513f536c5c68",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:03:44.178222Z",
     "start_time": "2024-07-02T09:03:31.407737Z"
    }
   },
   "id": "49d8c2bd95e8ddf5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceci est un test']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 11:10:30.948643: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.948719: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.949594: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.949672: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.950496: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.951717: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.951758: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:30.952123: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.192906: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.422723: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.422806: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.422910: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.422979: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.423057: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.423537: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.425694: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-07-02 11:10:31.431062: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.9818011   0.89277554  0.23231454  0.01589974  0.1806383   0.9957792\n",
      "  0.99798256  0.33106488 -0.02497336 -0.9987041  -0.09310168 -0.26330215]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.42536885 -0.0092841   0.90875703 ... -1.3789577   0.867938\n",
      "   0.19424458]\n",
      " [-0.43141297  0.13562825 -0.30347514 ... -1.0568973   0.5224188\n",
      "  -0.28293064]\n",
      " [-0.66645205 -0.39647132  0.6052308  ... -1.3264837   0.34678963\n",
      "   0.13612354]\n",
      " ...\n",
      " [-0.0633131   0.22402436  1.0188394  ... -0.84042495  0.38894445\n",
      "   0.20893508]\n",
      " [ 0.12264241  0.4450482   0.7040574  ... -0.84877586  0.8868514\n",
      "   0.201817  ]\n",
      " [ 0.1116228   0.3624912   0.81944793 ... -0.7872127   0.8446359\n",
      "   0.12332332]]\n"
     ]
    }
   ],
   "source": [
    "text = np.expand_dims(\"ceci est un test\", axis=0)\n",
    "print(text)\n",
    "text_encoded = bert_preprocess_model(text)\n",
    "text_encoded\n",
    "bert_results = bert_model(text_encoded)\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:10:31.628217Z",
     "start_time": "2024-07-02T09:10:30.523601Z"
    }
   },
   "id": "98bb3e5fa6526cfb",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "18856c657e08494f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"model\": \"mlp\",\n",
    "    \"embedder\": \"bert\",\n",
    "    \"embedding_data\": \"cc.fr.300.bin\",\n",
    "    \"dataset\": \"fr_hf.csv\",\n",
    "    \"batch_size\": 300\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.164642Z",
     "start_time": "2024-07-02T08:23:55.150600Z"
    }
   },
   "id": "9574abd306005981",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_folder_src = 'ml/ml_core/data/processed/'\n",
    "ml_core_folder_path = 'ml/ml_core/'\n",
    "data_path_src = f'{data_folder_src}{params_grid[\"dataset\"]}'\n",
    "date_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "experiment_name = f'deepwoke_{params_grid[\"embedder\"]}_{params_grid[\"model\"]}_{params_grid[\"dataset\"]}_{date_str}'\n",
    "\n",
    "log_dir = f\"{ml_core_folder_path}log/fit/{experiment_name}\"\n",
    "model_weight_dst = f'{ml_core_folder_path}model_weights/{experiment_name}-model.keras'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.179465Z",
     "start_time": "2024-07-02T08:23:55.167106Z"
    }
   },
   "id": "d220a1d10493404e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "vector_path = f'{ml_core_folder_path}embedded_vector/{params_grid[\"embedding_data\"]}_{params_grid[\"dataset\"]}'\n",
    "vector_x_dst = f'{vector_path}.x.npy'\n",
    "vector_y_dst = f'{vector_path}.y.npy'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.197409Z",
     "start_time": "2024-07-02T08:23:55.180790Z"
    }
   },
   "id": "63bc5b9857e00e2f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5d4209390b020a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda597a675bb1ba2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.304822Z",
     "start_time": "2024-07-02T08:23:55.198733Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.load(vector_x_dst)\n",
    "y = np.load(vector_y_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d86b3a33f2e60",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4811628c43744431",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:36:38.533439Z",
     "start_time": "2024-07-02T09:36:38.528734Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_classifier_model(output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "        #print(output_bias)\n",
    "\n",
    "    text_input = keras.layers.Input(shape=())\n",
    "    encoder_inputs = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')(text_input)\n",
    "    #encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = keras.layers.Dense(512, activation=\"relu\")(net)\n",
    "    net = keras.layers.Dropout(0.2)(net)\n",
    "    net = keras.layers.Dense(1, activation=\"sigmoid\", name='classifier')(net)\n",
    "    #net = keras.layers.Dense(3, activation=\"softmax\", name='classifier', bias_initializer=output_bias)(net)\n",
    "\n",
    "    return keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'preprocessing' (type KerasLayer).\n\nA KerasTensor is symbolic: it's a placeholder for a shape an a dtype. It doesn't have any actual numerical value. You cannot convert it to a NumPy array.\n\nCall arguments received by layer 'preprocessing' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=float32, sparse=None, name=keras_tensor_2>\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_classifier_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m, in \u001B[0;36mbuild_classifier_model\u001B[0;34m(output_bias)\u001B[0m\n\u001B[1;32m      6\u001B[0m text_input \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m())\n\u001B[1;32m      7\u001B[0m preprocessing_layer \u001B[38;5;241m=\u001B[39m hub\u001B[38;5;241m.\u001B[39mKerasLayer(tfhub_handle_preprocess, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpreprocessing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m encoder_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessing_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m encoder \u001B[38;5;241m=\u001B[39m hub\u001B[38;5;241m.\u001B[39mKerasLayer(tfhub_handle_encoder, trainable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBERT_encoder\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     10\u001B[0m outputs \u001B[38;5;241m=\u001B[39m encoder(encoder_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:250\u001B[0m, in \u001B[0;36mKerasLayer.call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m    247\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;66;03m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 250\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43msmart_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msmart_cond\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;66;03m# Unwrap dicts returned by signatures.\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_key:\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:252\u001B[0m, in \u001B[0;36mKerasLayer.call.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    247\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;66;03m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    250\u001B[0m   result \u001B[38;5;241m=\u001B[39m smart_cond\u001B[38;5;241m.\u001B[39msmart_cond(training,\n\u001B[1;32m    251\u001B[0m                                  \u001B[38;5;28;01mlambda\u001B[39;00m: f(training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[0;32m--> 252\u001B[0m                                  \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;66;03m# Unwrap dicts returned by signatures.\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_key:\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:583\u001B[0m, in \u001B[0;36mcanonicalize_to_monomorphic\u001B[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001B[0m\n\u001B[1;32m    577\u001B[0m       parameters\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    578\u001B[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001B[1;32m    579\u001B[0m                                      Parameter\u001B[38;5;241m.\u001B[39mKEYWORD_ONLY, type_context,\n\u001B[1;32m    580\u001B[0m                                      poly_parameter\u001B[38;5;241m.\u001B[39mtype_constraint))\n\u001B[1;32m    581\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    582\u001B[0m     parameters\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 583\u001B[0m         \u001B[43m_make_validated_mono_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoly_parameter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    584\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mtype_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mpoly_parameter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype_constraint\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:522\u001B[0m, in \u001B[0;36m_make_validated_mono_param\u001B[0;34m(name, value, kind, type_context, poly_type)\u001B[0m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_validated_mono_param\u001B[39m(\n\u001B[1;32m    519\u001B[0m     name, value, kind, type_context, poly_type\n\u001B[1;32m    520\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Parameter:\n\u001B[1;32m    521\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 522\u001B[0m   mono_type \u001B[38;5;241m=\u001B[39m \u001B[43mtrace_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtype_context\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    524\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m poly_type \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mono_type\u001B[38;5;241m.\u001B[39mis_subtype_of(poly_type):\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` was expected to be of type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    526\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpoly_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m but is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmono_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:185\u001B[0m, in \u001B[0;36mfrom_value\u001B[0;34m(value, context)\u001B[0m\n\u001B[1;32m    178\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m default_types\u001B[38;5;241m.\u001B[39mAttrs\u001B[38;5;241m.\u001B[39mfrom_type_and_attributes(\n\u001B[1;32m    179\u001B[0m       \u001B[38;5;28mtype\u001B[39m(value),\n\u001B[1;32m    180\u001B[0m       \u001B[38;5;28mtuple\u001B[39m(\n\u001B[1;32m    181\u001B[0m           from_value(\u001B[38;5;28mgetattr\u001B[39m(value, a\u001B[38;5;241m.\u001B[39mname), context)\n\u001B[1;32m    182\u001B[0m           \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__attrs_attrs__))\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m util\u001B[38;5;241m.\u001B[39mis_np_ndarray(value):\n\u001B[0;32m--> 185\u001B[0m   ndarray \u001B[38;5;241m=\u001B[39m \u001B[43mvalue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__array__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m default_types\u001B[38;5;241m.\u001B[39mTENSOR(ndarray\u001B[38;5;241m.\u001B[39mshape, ndarray\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, custom_nest_protocol\u001B[38;5;241m.\u001B[39mCustomNestProtocol):\n",
      "File \u001B[0;32m~/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/keras_core/src/backend/common/keras_tensor.py:62\u001B[0m, in \u001B[0;36mKerasTensor.__array__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 62\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA KerasTensor is symbolic: it\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms a placeholder for a shape \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     64\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man a dtype. It doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have any actual numerical value. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot convert it to a NumPy array.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer 'preprocessing' (type KerasLayer).\n\nA KerasTensor is symbolic: it's a placeholder for a shape an a dtype. It doesn't have any actual numerical value. You cannot convert it to a NumPy array.\n\nCall arguments received by layer 'preprocessing' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=float32, sparse=None, name=keras_tensor_2>\n  • training=None"
     ]
    }
   ],
   "source": [
    "model = build_classifier_model()\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:36:41.557383Z",
     "start_time": "2024-07-02T09:36:39.671101Z"
    }
   },
   "id": "413b8bee8008c271",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "7b718cecf9585fb1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## building and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ac62597164bde",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336209aae383296f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.312715Z",
     "start_time": "2024-07-02T08:23:55.309867Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    monitor='loss'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f93ecb4efe31443",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.327805Z",
     "start_time": "2024-07-02T08:23:55.314134Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStoppingLogging(keras.callbacks.Callback):\n",
    "    def __init__(self, early_stopping_callback, log_dir):\n",
    "        super().__init__()\n",
    "        self.early_stopping = early_stopping_callback\n",
    "        self.stopped_epoch = 0\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.early_stopping.stopped_epoch > 0:\n",
    "            self.stopped_epoch = self.early_stopping.stopped_epoch\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.scalar('early_stopping_epoch', self.stopped_epoch, step=epoch)\n",
    "                self.writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec43b4117399510",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.621564Z",
     "start_time": "2024-07-02T08:23:55.330209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:23:55.452906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.496078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.496114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.497678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.497713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.497730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.603022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.603071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.603078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 10:23:55.603104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:23:55.603123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_logging_callback = EarlyStoppingLogging(early_stopping, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3d46724d8e5aa1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:23:55.626860Z",
     "start_time": "2024-07-02T08:23:55.623070Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = [\n",
    "    early_stopping,\n",
    "    tensorboard_callback,\n",
    "    hp.KerasCallback(log_dir, params_grid),\n",
    "    early_stopping_logging_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec354f696f24a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <Functional name=functional_1, built=True>>\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:23:57.700603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc159130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-02 10:23:57.700644: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-07-02 10:23:57.724326: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-02 10:23:57.931106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m45/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6841 - loss: 0.6301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:23:59.668129: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 57ms/step - accuracy: 0.6898 - loss: 0.6257 - val_accuracy: 0.7687 - val_loss: 0.5361\n",
      "Epoch 2/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7648 - loss: 0.5363 - val_accuracy: 0.7687 - val_loss: 0.5097\n",
      "Epoch 3/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7634 - loss: 0.5099 - val_accuracy: 0.7687 - val_loss: 0.5007\n",
      "Epoch 4/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7647 - loss: 0.4968 - val_accuracy: 0.7697 - val_loss: 0.4821\n",
      "Epoch 5/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7646 - loss: 0.4858 - val_accuracy: 0.7833 - val_loss: 0.4735\n",
      "Epoch 6/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7839 - loss: 0.4628 - val_accuracy: 0.7792 - val_loss: 0.4688\n",
      "Epoch 7/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7872 - loss: 0.4495 - val_accuracy: 0.7869 - val_loss: 0.4649\n",
      "Epoch 8/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7950 - loss: 0.4469 - val_accuracy: 0.7872 - val_loss: 0.4614\n",
      "Epoch 9/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8002 - loss: 0.4365 - val_accuracy: 0.7838 - val_loss: 0.4653\n",
      "Epoch 10/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8014 - loss: 0.4339 - val_accuracy: 0.7849 - val_loss: 0.4637\n",
      "Epoch 11/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8090 - loss: 0.4230 - val_accuracy: 0.7818 - val_loss: 0.4796\n",
      "Epoch 12/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8030 - loss: 0.4223 - val_accuracy: 0.7562 - val_loss: 0.4990\n",
      "Epoch 13/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8108 - loss: 0.4159 - val_accuracy: 0.7933 - val_loss: 0.4623\n",
      "Epoch 14/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8240 - loss: 0.3960 - val_accuracy: 0.7954 - val_loss: 0.4717\n",
      "Epoch 15/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8220 - loss: 0.3960 - val_accuracy: 0.7931 - val_loss: 0.4687\n",
      "Epoch 16/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8281 - loss: 0.3833 - val_accuracy: 0.7926 - val_loss: 0.4826\n",
      "Epoch 17/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8263 - loss: 0.3783 - val_accuracy: 0.7949 - val_loss: 0.4790\n",
      "Epoch 18/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8353 - loss: 0.3684 - val_accuracy: 0.7949 - val_loss: 0.4861\n",
      "Epoch 19/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8436 - loss: 0.3601 - val_accuracy: 0.7877 - val_loss: 0.4940\n",
      "Epoch 20/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8467 - loss: 0.3463 - val_accuracy: 0.7882 - val_loss: 0.4917\n",
      "Epoch 21/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8521 - loss: 0.3400 - val_accuracy: 0.7864 - val_loss: 0.5030\n",
      "Epoch 22/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8636 - loss: 0.3211 - val_accuracy: 0.8008 - val_loss: 0.5215\n",
      "Epoch 23/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8611 - loss: 0.3198 - val_accuracy: 0.7831 - val_loss: 0.5183\n",
      "Epoch 24/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8666 - loss: 0.3100 - val_accuracy: 0.7897 - val_loss: 0.5336\n",
      "Epoch 25/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8664 - loss: 0.3118 - val_accuracy: 0.7836 - val_loss: 0.5374\n",
      "Epoch 26/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8734 - loss: 0.3000 - val_accuracy: 0.7913 - val_loss: 0.5458\n",
      "Epoch 27/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8771 - loss: 0.2914 - val_accuracy: 0.7826 - val_loss: 0.5477\n",
      "Epoch 28/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8794 - loss: 0.2846 - val_accuracy: 0.7951 - val_loss: 0.5764\n",
      "Epoch 29/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8816 - loss: 0.2793 - val_accuracy: 0.7785 - val_loss: 0.5731\n",
      "Epoch 30/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8866 - loss: 0.2703 - val_accuracy: 0.7792 - val_loss: 0.5884\n",
      "Epoch 31/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8925 - loss: 0.2593 - val_accuracy: 0.7872 - val_loss: 0.6044\n",
      "Epoch 32/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8973 - loss: 0.2447 - val_accuracy: 0.7782 - val_loss: 0.6145\n",
      "Epoch 33/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8987 - loss: 0.2446 - val_accuracy: 0.7713 - val_loss: 0.6349\n",
      "Epoch 34/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8948 - loss: 0.2439 - val_accuracy: 0.7792 - val_loss: 0.6261\n",
      "Epoch 35/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9021 - loss: 0.2367 - val_accuracy: 0.7846 - val_loss: 0.6390\n",
      "Epoch 36/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9144 - loss: 0.2123 - val_accuracy: 0.7815 - val_loss: 0.6491\n",
      "Epoch 37/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9135 - loss: 0.2163 - val_accuracy: 0.7844 - val_loss: 0.6662\n",
      "Epoch 38/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9085 - loss: 0.2217 - val_accuracy: 0.7826 - val_loss: 0.6756\n",
      "Epoch 39/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9152 - loss: 0.2105 - val_accuracy: 0.7831 - val_loss: 0.6695\n",
      "Epoch 40/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9192 - loss: 0.2051 - val_accuracy: 0.7703 - val_loss: 0.6906\n",
      "Epoch 41/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9190 - loss: 0.2047 - val_accuracy: 0.7833 - val_loss: 0.7156\n",
      "Epoch 42/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9126 - loss: 0.2075 - val_accuracy: 0.7862 - val_loss: 0.7040\n",
      "Epoch 43/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9211 - loss: 0.1923 - val_accuracy: 0.7713 - val_loss: 0.7311\n",
      "Epoch 44/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9284 - loss: 0.1907 - val_accuracy: 0.7856 - val_loss: 0.7331\n",
      "Epoch 45/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9280 - loss: 0.1877 - val_accuracy: 0.7803 - val_loss: 0.7432\n",
      "Epoch 46/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9311 - loss: 0.1735 - val_accuracy: 0.7854 - val_loss: 0.7668\n",
      "Epoch 47/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9284 - loss: 0.1790 - val_accuracy: 0.7633 - val_loss: 0.7760\n",
      "Epoch 48/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9316 - loss: 0.1746 - val_accuracy: 0.7651 - val_loss: 0.7970\n",
      "Epoch 49/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9284 - loss: 0.1778 - val_accuracy: 0.7744 - val_loss: 0.7950\n",
      "Epoch 50/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9357 - loss: 0.1664 - val_accuracy: 0.7790 - val_loss: 0.8043\n",
      "Epoch 51/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9355 - loss: 0.1683 - val_accuracy: 0.7849 - val_loss: 0.7956\n",
      "Epoch 52/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9349 - loss: 0.1717 - val_accuracy: 0.7672 - val_loss: 0.8171\n",
      "Epoch 53/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9398 - loss: 0.1588 - val_accuracy: 0.7751 - val_loss: 0.8215\n",
      "Epoch 54/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9352 - loss: 0.1617 - val_accuracy: 0.7574 - val_loss: 0.8376\n",
      "Epoch 55/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9403 - loss: 0.1558 - val_accuracy: 0.7795 - val_loss: 0.8408\n",
      "Epoch 56/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9394 - loss: 0.1507 - val_accuracy: 0.7685 - val_loss: 0.8505\n",
      "Epoch 57/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9413 - loss: 0.1498 - val_accuracy: 0.7736 - val_loss: 0.8518\n",
      "Epoch 58/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9477 - loss: 0.1376 - val_accuracy: 0.7751 - val_loss: 0.8704\n",
      "Epoch 59/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9472 - loss: 0.1377 - val_accuracy: 0.7746 - val_loss: 0.8617\n",
      "Epoch 60/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9509 - loss: 0.1345 - val_accuracy: 0.7777 - val_loss: 0.8652\n",
      "Epoch 61/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9548 - loss: 0.1268 - val_accuracy: 0.7782 - val_loss: 0.9144\n",
      "Epoch 62/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9549 - loss: 0.1240 - val_accuracy: 0.7636 - val_loss: 0.9125\n",
      "Epoch 63/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9507 - loss: 0.1275 - val_accuracy: 0.7731 - val_loss: 0.9086\n",
      "Epoch 64/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9563 - loss: 0.1191 - val_accuracy: 0.7554 - val_loss: 0.9268\n",
      "Epoch 65/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9500 - loss: 0.1312 - val_accuracy: 0.7790 - val_loss: 0.8992\n",
      "Epoch 66/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9576 - loss: 0.1151 - val_accuracy: 0.7800 - val_loss: 0.9015\n",
      "Epoch 67/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9543 - loss: 0.1252 - val_accuracy: 0.7677 - val_loss: 0.9412\n",
      "Epoch 68/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9534 - loss: 0.1202 - val_accuracy: 0.7733 - val_loss: 0.9129\n",
      "Epoch 69/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9540 - loss: 0.1217 - val_accuracy: 0.7515 - val_loss: 0.9945\n",
      "Epoch 70/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9521 - loss: 0.1313 - val_accuracy: 0.7769 - val_loss: 0.8997\n",
      "Epoch 71/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9605 - loss: 0.1163 - val_accuracy: 0.7736 - val_loss: 0.9462\n",
      "Epoch 72/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9570 - loss: 0.1168 - val_accuracy: 0.7546 - val_loss: 0.9430\n",
      "Epoch 73/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9570 - loss: 0.1162 - val_accuracy: 0.7628 - val_loss: 1.0073\n",
      "Epoch 74/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9564 - loss: 0.1171 - val_accuracy: 0.7869 - val_loss: 1.0095\n",
      "Epoch 75/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9528 - loss: 0.1258 - val_accuracy: 0.7736 - val_loss: 0.9401\n",
      "Epoch 76/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9625 - loss: 0.1135 - val_accuracy: 0.7615 - val_loss: 1.0031\n",
      "Epoch 77/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9661 - loss: 0.0965 - val_accuracy: 0.7721 - val_loss: 0.9976\n",
      "Epoch 78/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9597 - loss: 0.1126 - val_accuracy: 0.7828 - val_loss: 1.0015\n",
      "Epoch 79/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9660 - loss: 0.0955 - val_accuracy: 0.7695 - val_loss: 1.0170\n",
      "Epoch 80/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9646 - loss: 0.0980 - val_accuracy: 0.7723 - val_loss: 0.9933\n",
      "Epoch 81/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9675 - loss: 0.0942 - val_accuracy: 0.7662 - val_loss: 0.9819\n",
      "Epoch 82/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9633 - loss: 0.0994 - val_accuracy: 0.7749 - val_loss: 0.9890\n",
      "Epoch 83/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9644 - loss: 0.1032 - val_accuracy: 0.7728 - val_loss: 0.9683\n",
      "Epoch 84/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9657 - loss: 0.0949 - val_accuracy: 0.7785 - val_loss: 1.0286\n",
      "Epoch 85/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9690 - loss: 0.0873 - val_accuracy: 0.7754 - val_loss: 1.0247\n",
      "Epoch 86/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9678 - loss: 0.0872 - val_accuracy: 0.7764 - val_loss: 1.0836\n",
      "Epoch 87/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9695 - loss: 0.0881 - val_accuracy: 0.7774 - val_loss: 1.0716\n",
      "Epoch 88/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9667 - loss: 0.0903 - val_accuracy: 0.7779 - val_loss: 1.0493\n",
      "Epoch 89/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9675 - loss: 0.0951 - val_accuracy: 0.7687 - val_loss: 1.1107\n",
      "Epoch 90/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9666 - loss: 0.0966 - val_accuracy: 0.7797 - val_loss: 1.0473\n",
      "Epoch 91/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9646 - loss: 0.0986 - val_accuracy: 0.7810 - val_loss: 1.0539\n",
      "Epoch 92/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9719 - loss: 0.0842 - val_accuracy: 0.7805 - val_loss: 1.0582\n",
      "Epoch 93/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9637 - loss: 0.0987 - val_accuracy: 0.7767 - val_loss: 1.0404\n",
      "Epoch 94/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9696 - loss: 0.0915 - val_accuracy: 0.7646 - val_loss: 1.0653\n",
      "Epoch 95/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9671 - loss: 0.0930 - val_accuracy: 0.7700 - val_loss: 1.0941\n",
      "Epoch 96/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9651 - loss: 0.0925 - val_accuracy: 0.7741 - val_loss: 1.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras_core.src.callbacks.history.History at 0x7f058f1789d0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ml.ml_core.src.model.model_factory import model_factory\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#model = model_factory(params_grid['model'], 300, 1)\n",
    "# print(model.summary)\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# # model.add(keras.layers.Dense(127, input_dim=300, activation='relu'))\n",
    "# model.add(keras.layers.Dense(63, activation='relu'))\n",
    "# model.add(keras.layers.Dense(63, activation='relu'))\n",
    "# model.add(keras.layers.Dense(33, activation='relu'))\n",
    "# model.add(keras.layers.Dense(0, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#print(model.summary)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "          batch_size=params_grid['batch_size'],\n",
    "          callbacks=callback,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:37.839154Z",
     "start_time": "2024-07-02T08:23:55.628593Z"
    }
   },
   "id": "c4cf876c5cbae2f2",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "e01ea87c7efc4af6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b9fbafea831f00",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:47.630831Z",
     "start_time": "2024-07-02T08:24:47.585518Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(model_weight_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f1dcf54daf1ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### testing with custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9082729f7fb73c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:51.592703Z",
     "start_time": "2024-07-02T08:24:51.519853Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_weight_dst = f'../../model_weights/fasttext_nlp_20240613-131608-model.keras'\n",
    "new_model = load_model(model_weight_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be31f886c1e61d2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:25:18.496412Z",
     "start_time": "2024-07-02T08:24:53.682460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice output\n",
      "la bonjour je suis un type sympas : [[False]]\n",
      "[[0.00716593]]\n",
      "bonjour ça va les gens : [[False]]\n",
      "[[0.00271189]]\n",
      "j'aime pas trop ce mec : [[False]]\n",
      "[[1.9822155e-05]]\n",
      "cette meuf est cool : [[False]]\n",
      "[[7.958688e-08]]\n",
      "les meuf sont trop cool : [[False]]\n",
      "[[3.9379524e-11]]\n",
      "les mecs sont des gens stylé : [[False]]\n",
      "[[1.0103315e-05]]\n",
      "le mec est stylé : [[False]]\n",
      "[[3.5561166e-06]]\n",
      "nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse : [[False]]\n",
      "[[0.01031799]]\n",
      "les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste : [[ True]]\n",
      "[[0.9999633]]\n",
      "Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions : [[ True]]\n",
      "[[0.99984384]]\n",
      "\n",
      "\n",
      "not nice output\n",
      "regarde moi cette connasse : [[False]]\n",
      "[[0.02953639]]\n",
      "les femme leur place c'est à la cuisine : [[False]]\n",
      "[[0.01907552]]\n",
      "femme au volant, accident : [[False]]\n",
      "[[0.00229132]]\n",
      "les femmes on peux pas leur faire confiance : [[False]]\n",
      "[[0.01183499]]\n",
      "Pour une transphobe son passing est pas ouf : [[False]]\n",
      "[[0.0003371]]\n",
      "Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants : [[False]]\n",
      "[[0.4884769]]\n",
      "Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ???? : [[ True]]\n",
      "[[0.67932177]]\n",
      "Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête : [[False]]\n",
      "[[0.06251422]]\n",
      "les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes : [[ True]]\n",
      "[[0.97776926]]\n",
      "Oh les grosses tepus : [[False]]\n",
      "[[1.4216399e-10]]\n",
      "Faut pas t'étonner si tu te fais violer vu comment t'es habillée : [[False]]\n",
      "[[0.01328207]]\n",
      "Tu deverais avoir des enfants maintenant avant que ce soit trop tard : [[False]]\n",
      "[[0.08296497]]\n",
      "Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins : [[False]]\n",
      "[[0.17670663]]\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('ml/ml_core/data/embedding_data/cc.fr.300.bin')\n",
    "\n",
    "\n",
    "from ml.ml_core.src.embedding.embedding_utils import text_to_vector\n",
    "\n",
    "text_nice = [\n",
    "    \"la bonjour je suis un type sympas\",\n",
    "    \"bonjour ça va les gens\",\n",
    "    \"j'aime pas trop ce mec\",\n",
    "    \"cette meuf est cool\",\n",
    "    \"les meuf sont trop cool\",\n",
    "    \"les mecs sont des gens stylé\",\n",
    "    \"le mec est stylé\",\n",
    "    \"nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse\",\n",
    "    \"les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste\",\n",
    "    \"Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions\"\n",
    "\n",
    "]\n",
    "\n",
    "text_no_nice = [\n",
    "    \"regarde moi cette connasse\",\n",
    "    \"les femme leur place c'est à la cuisine\",\n",
    "    \"femme au volant, accident\",\n",
    "    \"les femmes on peux pas leur faire confiance\",\n",
    "    \"Pour une transphobe son passing est pas ouf\",\n",
    "    \"Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants\",\n",
    "    \"Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ????\",\n",
    "    \"Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête\",\n",
    "    \"les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes\",\n",
    "    \"Oh les grosses tepus\",\n",
    "    \"Faut pas t'étonner si tu te fais violer vu comment t'es habillée\",\n",
    "    \"Tu deverais avoir des enfants maintenant avant que ce soit trop tard\",\n",
    "    \"Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins\"\n",
    "]\n",
    "wordsvec_nice = [np.expand_dims(text_to_vector(text, ft), axis=0) for text in text_nice]\n",
    "wordsvec_no_nice = [np.expand_dims(text_to_vector(text, ft), axis=0) for text in text_no_nice]\n",
    "\n",
    "print(\"nice output\")\n",
    "for i in range(0, len(wordsvec_nice)):\n",
    "    prediction = new_model.predict(wordsvec_nice[i], verbose=False)\n",
    "    print(f\"{text_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")\n",
    "\n",
    "print(\"\\n\\nnot nice output\")\n",
    "for i in range(0, len(wordsvec_no_nice)):\n",
    "    prediction = new_model.predict(wordsvec_no_nice[i], verbose=False)\n",
    "    print(f\"{text_no_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee4f2d23f45322e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:47.579294Z",
     "start_time": "2024-07-02T08:24:47.576806Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c753464d73b3dba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:24:47.583103Z",
     "start_time": "2024-07-02T08:24:47.580900Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
