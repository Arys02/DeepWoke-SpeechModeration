{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['run.sh',\n 'requirements.txt',\n 'ml',\n '.idea',\n 'bot_discord',\n 'venv',\n '.git',\n 'log',\n '.gitignore']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "if '.git' not in os.listdir(): \n",
    "    os.chdir('./../../../../')\n",
    "os.listdir()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:52.269457Z",
     "start_time": "2024-07-02T08:13:52.261251Z"
    }
   },
   "id": "252f1bc47a6726ac",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.202061Z",
     "start_time": "2024-07-02T08:13:52.271212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:13:53.309357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 10:13:53.309407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 10:13:53.309442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 10:13:53.320736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "import fasttext\n",
    "import keras_core as keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_core.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboard.plugins.hparams import api as hp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d946bd3803cbf47",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import fastTest model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.208257Z",
     "start_time": "2024-07-02T08:13:58.204347Z"
    }
   },
   "id": "581097380ddb6dcb",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "18856c657e08494f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"model\": \"mlp\",\n",
    "    \"embedder\": \"fasttext\",\n",
    "    \"embedding_data\": \"cc.fr.300.bin\",\n",
    "    \"dataset\": \"fr_hf.csv\",\n",
    "    \"batch_size\": 300\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.223978Z",
     "start_time": "2024-07-02T08:13:58.209779Z"
    }
   },
   "id": "9574abd306005981",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_folder_src = 'ml/ml_core/data/processed/'\n",
    "ml_core_folder_path = 'ml/ml_core/'\n",
    "data_path_src = f'{data_folder_src}{params_grid[\"dataset\"]}'\n",
    "date_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "experiment_name = f'deepwoke_{params_grid[\"embedder\"]}_{params_grid[\"model\"]}_{params_grid[\"dataset\"]}_{date_str}'\n",
    "\n",
    "log_dir = f\"{ml_core_folder_path}log/fit/{experiment_name}\"\n",
    "model_weight_dst = f'{ml_core_folder_path}model_weights/{experiment_name}-model.keras'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.240038Z",
     "start_time": "2024-07-02T08:13:58.225945Z"
    }
   },
   "id": "d220a1d10493404e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "vector_path = f'{ml_core_folder_path}embedded_vector/{params_grid[\"embedding_data\"]}_{params_grid[\"dataset\"]}'\n",
    "vector_x_dst = f'{vector_path}.x.npy'\n",
    "vector_y_dst = f'{vector_path}.y.npy'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.257209Z",
     "start_time": "2024-07-02T08:13:58.241721Z"
    }
   },
   "id": "63bc5b9857e00e2f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5d4209390b020a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda597a675bb1ba2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.376359Z",
     "start_time": "2024-07-02T08:13:58.258643Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.load(vector_x_dst)\n",
    "y = np.load(vector_y_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d86b3a33f2e60",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4811628c43744431",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.380644Z",
     "start_time": "2024-07-02T08:13:58.378058Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b718cecf9585fb1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## building and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ac62597164bde",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336209aae383296f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.385483Z",
     "start_time": "2024-07-02T08:13:58.382262Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    monitor='loss'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f93ecb4efe31443",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.400965Z",
     "start_time": "2024-07-02T08:13:58.387120Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStoppingLogging(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, early_stopping_callback, log_dir):\n",
    "        super().__init__()\n",
    "        self.early_stopping = early_stopping_callback\n",
    "        self.stopped_epoch = 0\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.early_stopping.stopped_epoch > 0:\n",
    "            self.stopped_epoch = self.early_stopping.stopped_epoch\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.scalar('early_stopping_epoch', self.stopped_epoch, step=epoch)\n",
    "                self.writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec43b4117399510",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.727502Z",
     "start_time": "2024-07-02T08:13:58.403706Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:13:58.544902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.592938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.592979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.595193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.595247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.595264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.707892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.707938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.707945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 10:13:58.707970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 10:13:58.707987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_logging_callback = EarlyStoppingLogging(early_stopping, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3d46724d8e5aa1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:13:58.732969Z",
     "start_time": "2024-07-02T08:13:58.728976Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = [\n",
    "    early_stopping,\n",
    "    tensorboard_callback,\n",
    "    hp.KerasCallback(log_dir, params_grid),\n",
    "    early_stopping_logging_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec354f696f24a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <Functional name=functional_1, built=True>>\n",
      "<bound method Model.summary of <Sequential name=sequential, built=True>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arys/miniconda3/envs/DEV_IA/lib/python3.10/site-packages/keras_core/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:14:01.189646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x910d520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-02 10:14:01.189687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-07-02 10:14:01.215919: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-02 10:14:01.353301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m36/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.2409 - loss: 412.2628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:14:02.040383: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 33ms/step - accuracy: 0.2405 - loss: 411.2651 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 2/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.2426 - loss: 414.8920 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 3/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.2382 - loss: 407.4946 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 4/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.2404 - loss: 410.9908 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 5/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2414 - loss: 412.8482 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 6/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2402 - loss: 410.5568 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 7/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.2373 - loss: 405.8844 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 8/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2316 - loss: 395.9778 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 9/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2397 - loss: 409.7474 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 10/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.2450 - loss: 419.0119 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 11/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2382 - loss: 407.3999 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 12/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2407 - loss: 411.7132 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 13/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2441 - loss: 417.3945 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 14/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.2371 - loss: 405.4310 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 15/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2436 - loss: 416.5606 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 16/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2376 - loss: 406.0835 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 17/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.2348 - loss: 401.4213 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 18/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.2386 - loss: 408.0545 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 19/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2361 - loss: 403.6453 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 20/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2364 - loss: 404.2019 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 21/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2411 - loss: 412.2580 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 22/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2378 - loss: 406.4976 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 23/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2369 - loss: 404.9947 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 24/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.2396 - loss: 409.7899 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 25/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2377 - loss: 406.4763 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 26/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2373 - loss: 405.6767 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 27/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2424 - loss: 414.4247 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 28/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2402 - loss: 410.7596 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 29/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2369 - loss: 405.1505 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 30/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.2384 - loss: 407.6362 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 31/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.2426 - loss: 414.6954 - val_accuracy: 0.2313 - val_loss: 387.1880\n",
      "Epoch 32/500\n",
      "\u001B[1m49/49\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2414 - loss: 412.7358 - val_accuracy: 0.2313 - val_loss: 387.1880\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras_core.src.callbacks.history.History at 0x7f1c07b27f70>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ml.ml_core.src.model.model_factory import model_factory\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = model_factory(params_grid['model'], 300, 1)\n",
    "print(model.summary)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(128, input_dim=300, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(34, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "          batch_size=params_grid['batch_size'],\n",
    "          callbacks=callback,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:15.601786Z",
     "start_time": "2024-07-02T08:13:58.734548Z"
    }
   },
   "id": "c4cf876c5cbae2f2",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "e01ea87c7efc4af6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b9fbafea831f00",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:15.635873Z",
     "start_time": "2024-07-02T08:14:15.603604Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(model_weight_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f1dcf54daf1ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### testing with custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9082729f7fb73c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:15.717581Z",
     "start_time": "2024-07-02T08:14:15.637532Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_weight_dst = f'../../model_weights/fasttext_nlp_20240613-131608-model.keras'\n",
    "new_model = load_model(model_weight_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be31f886c1e61d2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:28.930603Z",
     "start_time": "2024-07-02T08:14:15.719291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice output\n",
      "la bonjour je suis un type sympas : [[ True]]\n",
      "[[1.]]\n",
      "bonjour ça va les gens : [[ True]]\n",
      "[[1.]]\n",
      "j'aime pas trop ce mec : [[ True]]\n",
      "[[1.]]\n",
      "cette meuf est cool : [[ True]]\n",
      "[[1.]]\n",
      "les meuf sont trop cool : [[ True]]\n",
      "[[1.]]\n",
      "les mecs sont des gens stylé : [[ True]]\n",
      "[[1.]]\n",
      "le mec est stylé : [[ True]]\n",
      "[[1.]]\n",
      "nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse : [[ True]]\n",
      "[[1.]]\n",
      "les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste : [[ True]]\n",
      "[[1.]]\n",
      "Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions : [[ True]]\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "not nice output\n",
      "regarde moi cette connasse : [[ True]]\n",
      "[[1.]]\n",
      "les femme leur place c'est à la cuisine : [[ True]]\n",
      "[[1.]]\n",
      "femme au volant, accident : [[ True]]\n",
      "[[1.]]\n",
      "les femmes on peux pas leur faire confiance : [[ True]]\n",
      "[[1.]]\n",
      "Pour une transphobe son passing est pas ouf : [[ True]]\n",
      "[[1.]]\n",
      "Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants : [[ True]]\n",
      "[[1.]]\n",
      "Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ???? : [[ True]]\n",
      "[[1.]]\n",
      "Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête : [[ True]]\n",
      "[[1.]]\n",
      "les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes : [[ True]]\n",
      "[[1.]]\n",
      "Oh les grosses tepus : [[ True]]\n",
      "[[1.]]\n",
      "Faut pas t'étonner si tu te fais violer vu comment t'es habillée : [[ True]]\n",
      "[[1.]]\n",
      "Tu deverais avoir des enfants maintenant avant que ce soit trop tard : [[ True]]\n",
      "[[1.]]\n",
      "Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins : [[ True]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('ml/ml_core/data/embedding_data/cc.fr.300.bin')\n",
    "\n",
    "\n",
    "from ml.ml_core.src.embedding.embedding_utils import text_to_vector\n",
    "\n",
    "text_nice = [\n",
    "    \"la bonjour je suis un type sympas\",\n",
    "    \"bonjour ça va les gens\",\n",
    "    \"j'aime pas trop ce mec\",\n",
    "    \"cette meuf est cool\",\n",
    "    \"les meuf sont trop cool\",\n",
    "    \"les mecs sont des gens stylé\",\n",
    "    \"le mec est stylé\",\n",
    "    \"nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse\",\n",
    "    \"les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste\",\n",
    "    \"Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions\"\n",
    "\n",
    "]\n",
    "\n",
    "text_no_nice = [\n",
    "    \"regarde moi cette connasse\",\n",
    "    \"les femme leur place c'est à la cuisine\",\n",
    "    \"femme au volant, accident\",\n",
    "    \"les femmes on peux pas leur faire confiance\",\n",
    "    \"Pour une transphobe son passing est pas ouf\",\n",
    "    \"Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants\",\n",
    "    \"Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ????\",\n",
    "    \"Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête\",\n",
    "    \"les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes\",\n",
    "    \"Oh les grosses tepus\",\n",
    "    \"Faut pas t'étonner si tu te fais violer vu comment t'es habillée\",\n",
    "    \"Tu deverais avoir des enfants maintenant avant que ce soit trop tard\",\n",
    "    \"Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins\"\n",
    "]\n",
    "wordsvec_nice = [np.expand_dims(text_to_vector(text, ft), axis=0) for text in text_nice]\n",
    "wordsvec_no_nice = [np.expand_dims(text_to_vector(text, ft), axis=0) for text in text_no_nice]\n",
    "\n",
    "print(\"nice output\")\n",
    "for i in range(0, len(wordsvec_nice)):\n",
    "    prediction = new_model.predict(wordsvec_nice[i], verbose=False)\n",
    "    print(f\"{text_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")\n",
    "\n",
    "print(\"\\n\\nnot nice output\")\n",
    "for i in range(0, len(wordsvec_no_nice)):\n",
    "    prediction = new_model.predict(wordsvec_no_nice[i], verbose=False)\n",
    "    print(f\"{text_no_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee4f2d23f45322e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:28.934103Z",
     "start_time": "2024-07-02T08:14:28.931894Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c753464d73b3dba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:14:28.937983Z",
     "start_time": "2024-07-02T08:14:28.935581Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
