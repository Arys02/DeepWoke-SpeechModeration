{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 19:14:08.254810: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 19:14:08.254861: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 19:14:08.254880: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 19:14:08.259505: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run.sh', 'requirements.txt', 'ml', '.idea', 'bot_discord', 'venv', '.git', 'log', '.gitignore']\n",
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, TFCamembertModel\n",
    "\n",
    "os.getcwd()\n",
    "if '.git' not in os.listdir():\n",
    "    os.chdir('./../../../')\n",
    "print(os.listdir())\n",
    "\n",
    "import fasttext\n",
    "import keras_core as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras_core import Sequential\n",
    "from keras_core.src.layers import Dense\n",
    "from keras_core.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T17:14:10.636517Z",
     "start_time": "2024-07-02T17:14:07.362446Z"
    }
   },
   "id": "6d11c9e02d10674",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 19:14:13.264225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.576241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.576320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.580635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.580700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.580725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.832276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.832323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.832330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 19:14:13.832355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 19:14:13.832372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFCamembertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFCamembertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFCamembertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"almanach/camembert-base\")\n",
    "model = TFCamembertModel.from_pretrained(\"almanach/camembert-base\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T17:14:16.356060Z",
     "start_time": "2024-07-02T17:14:12.410650Z"
    }
   },
   "id": "49863d9ff5308a71",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def encode_texts(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    outputs2 = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return outputs2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T17:14:16.361004Z",
     "start_time": "2024-07-02T17:14:16.358009Z"
    }
   },
   "id": "e5388776dee41d35",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "new_model = load_model(\"ml/ml_core/model_weights/deepwoke_camembert_convnet_fr_hf.csv_20240702-185649-model.keras\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T17:14:16.500924Z",
     "start_time": "2024-07-02T17:14:16.362457Z"
    }
   },
   "id": "6e389d0dcf44af48",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T17:14:23.423940Z",
     "start_time": "2024-07-02T17:14:16.502887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 19:14:21.081500: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xbb0b890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-02 19:14:21.081538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-07-02 19:14:21.094676: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-02 19:14:21.148450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-07-02 19:14:22.640587: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la bonjour je suis un type sympas : [[False]]\n",
      "[[0.20371594]]\n",
      "bonjour ça va les gens : [[False]]\n",
      "[[0.00084072]]\n",
      "j'aime pas trop ce mec : [[False]]\n",
      "[[0.0016064]]\n",
      "cette meuf est cool : [[False]]\n",
      "[[0.03134812]]\n",
      "les meuf sont trop cool : [[False]]\n",
      "[[0.05459661]]\n",
      "les mecs sont des gens stylé : [[False]]\n",
      "[[0.07510686]]\n",
      "le mec est stylé : [[False]]\n",
      "[[0.11929245]]\n",
      "nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse : [[False]]\n",
      "[[0.12536441]]\n",
      "les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste : [[ True]]\n",
      "[[0.9910994]]\n",
      "Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions : [[ True]]\n",
      "[[0.991222]]\n",
      "\n",
      "\n",
      "not nice output\n",
      "regarde moi cette connasse : [[False]]\n",
      "[[0.00036517]]\n",
      "les femme leur place c'est à la cuisine : [[ True]]\n",
      "[[0.9205499]]\n",
      "femme au volant, accident : [[False]]\n",
      "[[0.27139944]]\n",
      "les femmes on peux pas leur faire confiance : [[ True]]\n",
      "[[0.9429452]]\n",
      "Pour une transphobe son passing est pas ouf : [[ True]]\n",
      "[[0.89716464]]\n",
      "Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants : [[False]]\n",
      "[[0.00600254]]\n",
      "Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ???? : [[ True]]\n",
      "[[0.5363991]]\n",
      "Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête : [[ True]]\n",
      "[[0.99042374]]\n",
      "les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes : [[False]]\n",
      "[[0.00801438]]\n",
      "Oh les grosses tepus : [[False]]\n",
      "[[0.02409063]]\n",
      "Faut pas t'étonner si tu te fais violer vu comment t'es habillée : [[ True]]\n",
      "[[0.99138945]]\n",
      "Tu deverais avoir des enfants maintenant avant que ce soit trop tard : [[False]]\n",
      "[[0.00473992]]\n",
      "Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins : [[False]]\n",
      "[[0.01671064]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_nice = [\n",
    "    \"la bonjour je suis un type sympas\",\n",
    "    \"bonjour ça va les gens\",\n",
    "    \"j'aime pas trop ce mec\",\n",
    "    \"cette meuf est cool\",\n",
    "    \"les meuf sont trop cool\",\n",
    "    \"les mecs sont des gens stylé\",\n",
    "    \"le mec est stylé\",\n",
    "    \"nan mais mon manager exagère quand il dit que je suis pas assez productif et que je travail pas assez, franchement il abuse\",\n",
    "    \"les hommes cis sont toxiques pour la société car ils imposent leur vision paternaliste\",\n",
    "    \"Les hommes sont moins matures que les femmes quand il s'agit de prendre des décisions\"\n",
    "\n",
    "]\n",
    "\n",
    "text_no_nice = [\n",
    "    \"regarde moi cette connasse\",\n",
    "    \"les femme leur place c'est à la cuisine\",\n",
    "    \"femme au volant, accident\",\n",
    "    \"les femmes on peux pas leur faire confiance\",\n",
    "    \"Pour une transphobe son passing est pas ouf\",\n",
    "    \"Elle l’ouvre quand même beaucoup celle là pour quelqu’un qu’est pas capable d’éduquer ses enfants\",\n",
    "    \"Dis donc, c’est pas parce que t’es mal baisée que tu peux tout te permettre ????\",\n",
    "    \"Moi ce que j’aime bien chez les filles comme toi c’est que t’es pas du genre prise de tête\",\n",
    "    \"les femmes c'est comme le fromage, quand elles puent c'est qu'elles sont bonnes\",\n",
    "    \"Oh les grosses tepus\",\n",
    "    \"Faut pas t'étonner si tu te fais violer vu comment t'es habillée\",\n",
    "    \"Tu deverais avoir des enfants maintenant avant que ce soit trop tard\",\n",
    "    \"Vous seriez une collaboratrice idéal pour notre entreprise, malheureusement nous cherchons quelqu’un disponible sur le long terme, et nous craignons qu’à votre âge des changements familiaux ne vous permettent plus de vous investir autant que besoins\"\n",
    "]\n",
    "wordsvec_nice = [np.expand_dims(encode_texts(text), axis=0) for text in text_nice]\n",
    "wordsvec_no_nice = [np.expand_dims(encode_texts(text), axis=0) for text in text_no_nice]\n",
    "\n",
    "print(\"nice output\")\n",
    "for i in range(0, len(wordsvec_nice)):\n",
    "    prediction = new_model.predict(wordsvec_nice[i], verbose=False)\n",
    "    print(f\"{text_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nnot nice output\")\n",
    "for i in range(0, len(wordsvec_no_nice)):\n",
    "    prediction =  new_model.predict(wordsvec_no_nice[i], verbose=False)\n",
    "    print(f\"{text_no_nice[i]} : {prediction > 0.5}\")\n",
    "    print(f\"{prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b3203bf300f99b72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
